# app/api/fuid_corregido.py
from fastapi import APIRouter, UploadFile, File, HTTPException, Depends, Form
from sqlalchemy.orm import Session
from pydantic import BaseModel
import logging
import tempfile
import os
from pathlib import Path
import hashlib
from app.database import get_db
from app.services.ia_contextual_service import IAContextualService
from app.models.documento import Documento
from app.models.fuid_models import ExpedienteFUID, FUID
from app.utils.fuid_generator import generate_fuid
from app.utils.hash_generator import generate_hash
from datetime import datetime
import shutil

router = APIRouter(tags=["FUID"])
logger = logging.getLogger(__name__)

class ProcesarURLRequest(BaseModel):
    url: str
    version: str = "1.0"

# ===============================
# ENDPOINT PARA URLs (ACTUALIZADO)
# ===============================
@router.post("/procesar-url")
async def procesar_url_fuid(
    request: ProcesarURLRequest,
    db: Session = Depends(get_db)
):
    """Procesa documentos desde URL/Google Drive con FUID - VERSI√ìN CON MOVIMIENTO DE ARCHIVOS"""
    try:
        from app.services.documentos_url_service import process_external_document
        
        logger.info(f"üåê PROCESANDO URL FUID: {request.url}")
        
        documentos_metadata = process_external_document(request.url, 1, request.version)
        
        if not documentos_metadata:
            raise HTTPException(status_code=400, detail="No se obtuvieron documentos de la URL")
        
        resultados = []
        expedientes_creados = {}
        
        for metadata in documentos_metadata:
            try:
                ruta_archivo = metadata["ruta_guardado"]
                nombre_archivo = metadata["nombre_archivo"]
                
                logger.info(f"üìÑ Procesando: {nombre_archivo}")
                
                # Procesar con IA contextual
                ia_service = IAContextualService()
                resultado_ia = ia_service.clasificar_documento_contextual(
                    ruta_archivo, 
                    nombre_archivo
                )
                
                clasificacion = resultado_ia["clasificacion_principal"]
                unidad_documental = resultado_ia.get("unidad_documental", "No identificada")
                codigo = clasificacion["codigo"]
                
                logger.info(f"‚úÖ Clasificado: {nombre_archivo} -> {clasificacion['area']}/{clasificacion['serie']}")
                
                # Mover archivo f√≠sicamente a carpeta clasificada
                ruta_final = mover_archivo_a_carpeta_clasificada(
                    ruta_archivo, 
                    clasificacion, 
                    nombre_archivo
                )
                
                # Guardar documento en BD con la nueva ruta
                documento_db = Documento(
                    nombre_archivo=nombre_archivo,
                    ruta_guardado=ruta_final,
                    area=clasificacion["area"],
                    serie=clasificacion["serie"],
                    subserie=clasificacion["subserie"],
                    codigo_clasificacion=codigo,
                    confianza_clasificacion=clasificacion["confianza"],
                    palabras_clave_contextuales=", ".join(resultado_ia["analisis_contextual"]["palabras_clave_contextuales"]),
                    nombre_unidad_documental=unidad_documental,
                    usuario_id=1,
                    extension=metadata["extension"],
                    version=request.version,
                    tamano_kb=metadata["tamano_kb"],
                    hash_archivo=metadata["hash_archivo"]
                )
                
                db.add(documento_db)
                db.flush()
                
                # Agrupar por expediente 
                if codigo not in expedientes_creados:
                    expediente = crear_o_obtener_expediente(db, clasificacion, unidad_documental, 1)
                    
                    # VERIFICAR QUE EL EXPEDIENTE TENGA ID ANTES DE CREAR FUID
                    if not expediente.id:
                        logger.error(f"‚ùå Expediente sin ID para c√≥digo: {codigo}")
                        continue
                    
                    fuid = crear_fuid_para_expediente(db, expediente, 1)
                    expedientes_creados[codigo] = {
                        "expediente": expediente,
                        "fuid": fuid,
                        "documentos": []
                    }
                
                expedientes_creados[codigo]["documentos"].append(documento_db)
                expedientes_creados[codigo]["expediente"].cantidad_documentos += 1
                
                resultados.append({
                    "documento": nombre_archivo,
                    "clasificacion": clasificacion,
                    "unidad_documental": unidad_documental,
                    "confianza": clasificacion["confianza"],
                    "ruta_final": ruta_final
                })
                
            except Exception as e:
                logger.error(f"‚ùå Error procesando {metadata.get('nombre_archivo', 'desconocido')}: {str(e)}")
                continue
        
        # Si no se crearon expedientes, hacer rollback y retornar error
        if not expedientes_creados:
            db.rollback()
            raise HTTPException(status_code=500, detail="No se pudieron crear expedientes FUID")
        
        # Actualizar tama√±os de expedientes
        for codigo, data in expedientes_creados.items():
            total_size = sum(doc.tamano_kb for doc in data["documentos"]) / 1024
            data["expediente"].tama√±o_documentos = f"{total_size:.2f}MB"
        
        db.commit()
        
        logger.info(f"‚úÖ Procesamiento completado: {len(resultados)} documentos, {len(expedientes_creados)} expedientes")
        
        return {
            "estado": "completado",
            "mensaje": f"Procesados {len(resultados)} documentos con FUID",
            "procesados": len(resultados),
            "expedientes_creados": [
                {
                    "fuid": data["fuid"].numero_fuid,
                    "codigo": codigo,
                    "documentos": len(data["documentos"]),
                    "unidad_documental": data["expediente"].nombre_unidad_documental
                }
                for codigo, data in expedientes_creados.items()
            ],
            "resultados": resultados
        }
        
    except Exception as e:
        db.rollback()
        logger.error(f"‚ùå ERROR FUID URL: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error procesando URL: {str(e)}")

# ===============================
# ENDPOINT PARA ARCHIVOS LOCALES (ACTUALIZADO)
# ===============================
@router.post("/procesar-archivo")
async def procesar_archivo_fuid(
    file: UploadFile = File(...),
    version: str = Form("1.0"),
    db: Session = Depends(get_db)
):
    """Procesa un archivo individual con FUID e IA contextual - VERSI√ìN CON MOVIMIENTO DE ARCHIVOS"""
    try:
        logger.info(f"üöÄ INICIANDO FUID para: {file.filename}")
        
        # Validar tipo de archivo
        allowed_extensions = ['.pdf', '.docx', '.txt']
        file_extension = os.path.splitext(file.filename)[1].lower()
        
        if file_extension not in allowed_extensions:
            raise HTTPException(
                status_code=400, 
                detail=f"Formato no soportado. Use: {', '.join(allowed_extensions)}"
            )

        # Guardar archivo temporal
        with tempfile.NamedTemporaryFile(delete=False, suffix=file_extension) as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_path = tmp_file.name

        try:
            # Procesar con IA contextual 
            ia_service = IAContextualService()
            resultado_ia = ia_service.clasificar_documento_contextual(
                tmp_path, 
                file.filename
            )
            
            clasificacion = resultado_ia["clasificacion_principal"]
            unidad_documental = resultado_ia.get("unidad_documental", "No identificada")
            
            # VERIFICAR DUPLICADOS ANTES DE GUARDAR
            hash_archivo = hashlib.md5(content).hexdigest()
            documento_existente = db.query(Documento).filter(
                Documento.hash_archivo == hash_archivo
            ).first()
            
            if documento_existente:
                logger.info(f"üìÑ Usando documento existente: {documento_existente.id}")
                documento_db = documento_existente
                
                # Si el documento existe, usar su ruta actual
                ruta_final = documento_db.ruta_guardado
            else:
                # Mover archivo f√≠sicamente a carpeta clasificada
                ruta_final = mover_archivo_a_carpeta_clasificada(
                    tmp_path, 
                    clasificacion, 
                    file.filename
                )
                
                # Guardar documento en BD con la nueva ruta
                documento_db = Documento(
                    nombre_archivo=file.filename,
                    ruta_guardado=ruta_final,  
                    area=clasificacion["area"],
                    serie=clasificacion["serie"],
                    subserie=clasificacion["subserie"],
                    codigo_clasificacion=clasificacion["codigo"],
                    confianza_clasificacion=clasificacion["confianza"],
                    palabras_clave_contextuales=", ".join(resultado_ia["analisis_contextual"]["palabras_clave_contextuales"]),
                    nombre_unidad_documental=unidad_documental,
                    usuario_id=1,
                    extension=file_extension,
                    version=version,
                    tamano_kb=os.path.getsize(ruta_final) / 1024,  
                    hash_archivo=hash_archivo
                )
                db.add(documento_db)
            
            # FLUSH √öNICO para obtener IDs
            db.flush()
            
            # CREAR EXPEDIENTE FUID
            expediente = crear_o_obtener_expediente(db, clasificacion, unidad_documental, 1)
            
            # CREAR FUID
            fuid = crear_fuid_para_expediente(db, expediente, 1)
            
            # Actualizar expediente con documento
            expediente.cantidad_documentos = db.query(Documento).filter(
                Documento.codigo_clasificacion == expediente.codigo
            ).count()
            
            # Calcular tama√±o real
            tama√±o_total = db.query(Documento.tamano_kb).filter(
                Documento.codigo_clasificacion == expediente.codigo
            ).scalar() or 0
            expediente.tama√±o_documentos = f"{(tama√±o_total / 1024):.2f}MB"
            
            # COMMIT √öNICO al final
            db.commit()
            
            logger.info(f"‚úÖ FUID CREADO: {fuid.numero_fuid}")
            
            return {
                "estado": "completado",
                "fuid": fuid.numero_fuid,
                "expediente_id": expediente.id,
                "documento_id": documento_db.id,
                "clasificacion": clasificacion,
                "unidad_documental": unidad_documental,
                "confianza": clasificacion["confianza"],
                "ruta_final": ruta_final
            }
            
        finally:
            # Limpiar archivo temporal SOLO si no fue movido
            if os.path.exists(tmp_path) and tmp_path != ruta_final:
                os.unlink(tmp_path)
                logger.info(f"üßπ Archivo temporal eliminado: {tmp_path}")
        
    except Exception as e:
        db.rollback()
        logger.error(f"‚ùå ERROR FUID: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error en FUID: {str(e)}")

# ===============================
# FUNCIONES AUXILIARES
# ===============================
def mover_archivo_a_carpeta_clasificada(ruta_original: str, clasificacion: dict, nombre_archivo: str) -> str:
    """Mueve f√≠sicamente el archivo a la carpeta clasificada"""
    try:
        # Crear estructura de carpetas
        ruta_carpeta = os.path.join(
            "uploads",
            clasificacion["area"],
            clasificacion["serie"]
        )
        
        # Crear carpeta si no existe
        os.makedirs(ruta_carpeta, exist_ok=True)
        
        # Ruta destino
        ruta_destino = os.path.join(ruta_carpeta, nombre_archivo)
        
        # Si el archivo ya est√° en la ubicaci√≥n correcta, no mover
        if ruta_original == ruta_destino:
            logger.info(f"üìÅ Archivo ya en ubicaci√≥n correcta: {ruta_destino}")
            return ruta_destino
        
        # Mover archivo
        if os.path.exists(ruta_original):
            shutil.move(ruta_original, ruta_destino)
            logger.info(f"üì¶ Archivo movido: {ruta_original} ‚Üí {ruta_destino}")
            return ruta_destino
        else:
            logger.warning(f"‚ö†Ô∏è Archivo original no encontrado: {ruta_original}")
            return ruta_original
            
    except Exception as e:
        logger.error(f"‚ùå Error moviendo archivo: {str(e)}")
        return ruta_original

def crear_o_obtener_expediente(db: Session, clasificacion: dict, unidad_documental: str, usuario_id: int):
    """Obtiene un expediente existente o crea uno nuevo - VERSI√ìN CORREGIDA"""
    codigo = clasificacion["codigo"]
    
    # BUSCAR CON .first() PARA EVITAR "Multiple rows"
    expediente = db.query(ExpedienteFUID).filter(
        ExpedienteFUID.codigo == codigo,
        ExpedienteFUID.usuario_id == usuario_id
    ).first()
    
    if expediente:
        logger.info(f"‚úÖ Expediente existente: {expediente.id}")
        return expediente
    
    # Crear nuevo expediente
    fecha_actual = datetime.now()
    expediente = ExpedienteFUID(
        codigo=codigo,
        nombre_series=clasificacion["serie"],
        nombre_subseries=clasificacion.get("subserie"),
        nombre_unidad_documental=unidad_documental,
        fecha_inicial=fecha_actual,
        fecha_final=fecha_actual,
        electronico=True,
        ubicacion=f"uploads/{clasificacion['area']}/{clasificacion['serie']}",
        cantidad_documentos=0,
        tama√±o_documentos="0MB",
        usuario_id=usuario_id
    )
    
    db.add(expediente)
    # HACER FLUSH PARA OBTENER EL ID
    db.flush()
    logger.info(f"‚úÖ Nuevo expediente creado con ID: {expediente.id}")
    
    return expediente

def crear_fuid_para_expediente(db: Session, expediente: ExpedienteFUID, usuario_id: int):
    """Crea un FUID para un expediente - VERSI√ìN CORREGIDA"""
    # Verificar si ya existe con .first()
    fuid_existente = db.query(FUID).filter(FUID.expediente_id == expediente.id).first()
    if fuid_existente:
        logger.info(f"‚úÖ FUID existente: {fuid_existente.numero_fuid}")
        return fuid_existente
    
    # Crear nuevo FUID
    metadatos_fuid = {
        "codigo": expediente.codigo,
        "nombre_series": expediente.nombre_series,
        "nombre_subseries": expediente.nombre_subseries,
        "nombre_unidad_documental": expediente.nombre_unidad_documental,
        "fecha_inicial": expediente.fecha_inicial.isoformat(),
        "fecha_final": expediente.fecha_final.isoformat(),
        "electronico": True,
        "ubicacion": expediente.ubicacion,
        "cantidad_documentos": expediente.cantidad_documentos,
        "tama√±o_documentos": expediente.tama√±o_documentos
    }
    
    numero_fuid = generate_fuid()
    hash_data = {
        "expediente_id": expediente.id,
        "usuario_id": usuario_id,
        "metadatos_fuid": metadatos_fuid,
        "timestamp": str(datetime.now().timestamp())
    }
    hash_fuid = generate_hash(hash_data)
    
    fuid = FUID(
        numero_fuid=numero_fuid,
        expediente_id=expediente.id,
        usuario_id=usuario_id,
        metadatos_fuid=metadatos_fuid,
        referencia_contenido=expediente.ubicacion,
        hash_fuid=hash_fuid
    )
    
    db.add(fuid)
    logger.info(f"‚úÖ Nuevo FUID creado: {numero_fuid} para expediente {expediente.id}")
    
    return fuid